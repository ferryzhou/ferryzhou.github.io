---
title: "reuse, tools, automation and scalability"
date: 2020-11-15
---

之前一直用colab

其实也知道colab可以调用python类库

但是每次做一个分析，colab实在是太方便，改完，run一下直接出结果

有时想对新的数据做分析，需要修改一下参数

还需要对前后数据做一些比较

要么改参数，运行，截图，对两个数据重复一遍这几个步骤

要么复制colab，分别该参数，分别运行

总觉得哪儿不对

虽然短期能把任务以最快速度完成

但是总觉得别扭

之前搜了一下reuse

发现colab里可以直接引用另外一个colab的cell

用了一下，感觉还可以，起码能解决reuse的问题

但是针对不同的数据还是每次得改参数，运行，截图

虽然方便，仍然需要手工，并且容易忘记之前做过哪些改动

昨天静下心来，尝试了把python函数写到code repo里去，在colab里再import

突然觉得世界清静了很多

首先，编辑器里可以直接format代码，语法错误高亮。在写代码这一层，效率提高很多。特别是对大规模代码。

其次，可以编译，提交，让队友审核，也可以让队友贡献和协作。在代码协作这一层，变得scalable

第三，在colab里import，这样其他人也可以直接调用，不用copy paste，也不用colab cell reuse。在代码使用这一层，变得scalable。

第四，可以写程序直接调用类库，对很多的数据同时进行分析，存图。在数据分析运行这一层，变得scalable

这里面有些步骤去掉了人工行为，把行为转移到了程序和机器，从而scalable，省去人的时间和精力。

有些步骤，比如code repo，library，降低了协作门槛，从而协作scalable。

也许，一个程序员的自我修养，就应当是一切程序化

让一个作品省自己时间，也省别人时间

软件本身就死这样一个伟大的发明

而互联网增加了一个新的维度

这个时代互联网程序员的高薪资，就是有scalability作为基础

另外，不同的tool特点不一样

对于prototype, colab可能很好

但是对于production，传统的code repo, compile, binary更好

错误的，或者是不合适的使用tool，都会导致效率的降低

一个人，到一个团队，再到一个公司，同样是scalability的提升

小的团队，flat结构可能效率最高

而大的公司，层级结构是必须
